# -*- coding: utf-8 -*-
"""Preprocessing Data

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w2VCNL90RTt-VFZP8SmFpSLELN5itQZ5

## IMPORT LIBRARY
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import BernoulliNB 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.multiclass import OneVsRestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import plot_confusion_matrix

pip install openpyxl

df = pd.read_excel('tokped_text.xlsx')
df

df.head()

import nltk
nltk.download('all')

"""## Data Preprocessing"""

df['Ulasan_clean'] = df['Ulasan_clean'].astype(str)
df['Ulasan_clean'] = df['Ulasan_clean'].str.lower()
data = df

data = data.drop(['Unnamed: 0'],axis=1)
data

import string 
import re 
from nltk.tokenize import word_tokenize 
from nltk.probability import FreqDist

def remove_links(text):
    # menghapus tab, new line, ans back slice
    text = text.replace('\\t'," ").replace('\\n'," ").replace('\\u'," ").replace('\\',"").replace('/'," ")
    # menghapus non ASCII (emoticon, chinese word, .etc)
    text = text.encode('ascii', 'replace').decode('ascii')
    # menghapus mention, link, hashtag
    text = ' '.join(re.sub("([@#][A-Za-z0-9]+)|(\w+:\/\/\S+)"," ", text).split())
    # menghapus URL
    return text.replace("http://", " ").replace("https://", " ")
                
data['Ulasan_clean'] = data['Ulasan_clean'].apply(remove_links)

# menghapus angka
def remove_number(text):
    return  re.sub(r"\d+", " ", text)

data['Ulasan_clean'] = data['Ulasan_clean'].apply(remove_number)

# menghapus tanda baca
def remove_punctuation(text):
  return re.sub(r'[^\w\s]', ' ', text)
  # return text.translate(str.maketrans("","",string.punctuation))

data['Ulasan_clean'] = data['Ulasan_clean'].apply(remove_punctuation)

data['Ulasan_clean']

# menghilangkan 1 huruf
def remove_singl_char(text):
  return re.sub(r"\b[a-zA-Z]\b", " ", text)

data['Ulasan_clean'] = data['Ulasan_clean'].apply(remove_singl_char)

# tokenisasi kata
def word_tokenize_wrapper(text):
    return word_tokenize(text)

data['Ulasan_tokenize'] = data['Ulasan_clean'].apply(word_tokenize_wrapper)

# menghitung jumlah frekuensi kata
def freqDist_wrapper(text):
    return FreqDist(text)

Ulasan_fqsist = data['Ulasan_tokenize'].apply(freqDist_wrapper)

print('Frequency Tokens : \n') 
print(Ulasan_fqsist.head().apply(lambda x : x.most_common()))

slank_word_dict = {
  "keduakali" : "kedua kali",
  "agak" : "sedikit",
  "pas" : "saat",
  "produkx" : "produknya",
  "sukamkasih" : "suka makasih",
  "gak" : "tidak",
  "cpt" : "cepat",
  "sdh" : "sudah",
  "recommend" : "rekomendasi",
  "hrga" : "harga",
  "bagusseller" : "bagus",
  "bagusssss" : "bagus",
  "bagussssss" : "bagus",
  "baguuussss" : "bagus",
  "cepatmakasih": "cepat",
  "cepatmantappp": "cepat",
  "cepatproduct": "cepat",
  "cepatrecomended": "cepat",
  "cepattoko": "cepat",
  "yg" : "yang",
  "recomended": "rekomendasi",
  "recommended": "rekomendasi",
  "rekomendasi": "rekomendasi",
  "rekomended": "rekomendasi",
  "bgt" : "banget",
  "packaging" : "kemasan",
  "packing" : "kemas",
  "pcs" : "pieces",
  "dgn" : "dengan",
  "dg" : "dengan",
  "sya" : "saya",
  "sy" : "saya",
  "order" : "pesanan",
  "mantab" : "mantap",
  "mantaps" : "mantap",
  "smoga" : "semoga",
  "thanks" : "terima kasih",
  "baguz" : "bagus",
  "sippp" : "sip",
  "tooop" : "top",
  "puuaaassss" : "puas",
  "puass" : "puas",
  "puasssss" : "puas",
  "menurit" : "menurut",
  "ikin" : "akan",
  "moga" : "semoga",
  "brngnya" : "barangnya",
  "brng" : "barang",
  "packagingnya" : "kemasannya",
  "packingnya" : "kemasnya",
  "tq" : "makasih",
  "late" : "terlambat",
  "mmasker" : "masker",
  "niattt" : "niat",
  "krn" : "karena",
  "makasihhhh" : "makasih",
  "anakanak" : "anak-anak",
  "sukaaaaa" : "suka",
  "krg" : "kurang",
  "kw" : "palsu",
  "nya" : " ",
  }
def slank_normalized_term(document):
    return [slank_word_dict[term] if term in slank_word_dict else term for term in document]

normalizad_word = pd.read_csv("colloquial-indonesian-lexicon.csv")
# membenarkan kata yang typo, berlebihan atau atau tidak baku
normalizad_word = normalizad_word.drop(['In-dictionary','context','category1','category2', 'category3'],axis = 1 )

normalizad_word_dict = {}

for index, row in normalizad_word.iterrows():
    if row[0] not in normalizad_word_dict:
        normalizad_word_dict[row[0]] = row[1] 

def normalized_term(document):
    return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]

data['Ulasan_normalized'] = data['Ulasan_tokenize'].apply(normalized_term).apply(slank_normalized_term)

data["Ulasan_clean"] = [' '.join(map(str, l)) for l in data['Ulasan_normalized']]

ulasan = ' '.join(str(v) for v in data['Ulasan_clean'])
tokenize_ulasan = word_tokenize(ulasan)

fqdist = FreqDist(tokenize_ulasan)
fqdist

fqdist.most_common(15)

data_label = data[["Ulasan_clean", "label"]]

"""## Visualisasi Data"""

sentimen_data=pd.value_counts(data_label["label"], sort= True)
sentimen_data.plot(kind= 'bar', color= ["green", "red"])
plt.title('Bar chart')
plt.show()

from wordcloud import WordCloud

train_s0 = data_label[data_label["label"] == 0]
train_s1 = data_label[data_label["label"] == 1]

train_s0["Ulasan_clean"] = train_s0["Ulasan_clean"].fillna("tidak ada komentar")
train_s1["Ulasan_clean"] = train_s1["Ulasan_clean"].fillna("tidak ada komentar")

all_text_s1 = ' '.join(word for word in train_s1["Ulasan_clean"])
wordcloud = WordCloud(colormap='Greens', width=1000, height=1000, mode='RGBA', background_color='white').generate(all_text_s1)
plt.figure(figsize=(20,10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.title("Ulasan Positif")
plt.margins(x=0, y=0)
plt.show()

all_text_s0 = ' '.join(word for word in train_s0["Ulasan_clean"])
wordcloud = WordCloud(colormap='Reds', width=1000, height=1000, mode='RGBA', background_color='white').generate(all_text_s0)
plt.figure(figsize=(20,10))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.margins(x=0, y=0)
plt.show()

data_label['Ulasan_clean'] = data_label['Ulasan_clean'].fillna("tidak ada komentar")

"""## Split Train test"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(data_label['Ulasan_clean'], data_label['label'], 
                                                    test_size=0.2, stratify=data_label['label'], random_state=42)

temp_train = X_train
temp_test = X_test

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(decode_error='replace', encoding='utf-8')
X_train = vectorizer.fit_transform(X_train)
X_test = vectorizer.transform(X_test)

print(X_train.shape)
print(X_test.shape)

X_train = X_train.toarray()
X_test = X_test.toarray()

"""## Model"""

# logreg_cv = LogisticRegression(random_state=0)
# dt_cv=DecisionTreeClassifier()
# knn_cv=KNeighborsClassifier()
# svc_cv=SVC()
# nb_cv=BernoulliNB()
# rfc = RandomForestClassifier()
# cv_dict = {0: 'Logistic Regression', 1: 'Decision Tree',2:'KNN',3:'SVC',4:'Naive Bayes',5:'Random Forest'}
# cv_models=[logreg_cv,dt_cv,knn_cv,svc_cv,nb_cv,rfc]


# for i,model in enumerate(cv_models):
#     print("{} Test Accuracy: {}".format(cv_dict[i],cross_val_score(model,
#     X_train, y_train , cv=10, scoring ='accuracy').mean()))

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
svm = SVC(kernel='rbf')
svm.fit(X_train, y_train)
y_pred_svc = svm.predict(X_test)
print('--------------------- confusion matrix  ----------------------------')
plot_confusion_matrix(svm, X_test, y_test)  
plt.show()
print('--------------------- classification report  ----------------------------')
print(classification_report(y_test, y_pred_svc))

dict = {'ulasan' : temp_test,
        'label' : y_test,
        'prediksi' : y_pred_svc}
show = pd.DataFrame(dict)
display(show)

# komplen, capek

label2 = show['label'].to_numpy()
prediksi2 = show['prediksi'].to_numpy()
ulasan2 = show['ulasan'].to_numpy()

for index in range(show.shape[0]):
  if label2[index] != prediksi2[index]:
    print("{}. {} {} {}".format(index, label2[index],prediksi2[index],ulasan2[index]))

# bekas, ringkih,
pred = 'batman'
teks_vect = vectorizer.transform([pred])
teks_vect = teks_vect.toarray()
print(svm.predict(teks_vect))