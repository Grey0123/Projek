{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xq-IHfAQ15A7",
        "outputId": "0a3f6b0f-0985-42c5-f78f-402c45cb6d4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'Data-generator-for-CRNN'...\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/VikasOjha666/Data-generator-for-CRNN.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EF8dOm49v1zE",
        "outputId": "25d6e0ea-d47b-41f3-ee12-6c00e3f718e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Semester 5\\Computer Vision\\OCR\\Data-generator-for-CRNN\n"
          ]
        }
      ],
      "source": [
        "%cd Data-generator-for-CRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YYT7zH6n394M"
      },
      "outputs": [],
      "source": [
        "!mkdir images\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bL_25u1_4DnB"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "generate_data.py:127: DeprecationWarning: getsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use getbbox or getlength instead.\n",
            "  w,h=font.getsize(word)[0],font.getsize(word)[1]\n"
          ]
        }
      ],
      "source": [
        "!python generate_data.py --n_samples 300000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0At5jRxlj0TN"
      },
      "outputs": [],
      "source": [
        "import fnmatch\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import time\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UwcIFwjg4IN-"
      },
      "outputs": [],
      "source": [
        "from keras.utils import pad_sequences\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oNmZv6iY4Loh"
      },
      "outputs": [],
      "source": [
        "char_list = string.ascii_letters+string.digits\n",
        "\n",
        "#  Encode semua output menjadi digit\n",
        "def encode(txt):\n",
        "\n",
        "    dig_lst = [] \n",
        "    for index, char in enumerate(txt):\n",
        "      # test jika index(char)\n",
        "        try:\n",
        "            dig_lst.append(char_list.index(char))\n",
        "        except:\n",
        "            print(char)\n",
        "        \n",
        "    return dig_lst\n",
        "\n",
        "def find_dominant_color(image):\n",
        "        # Resize Image\n",
        "        width, height = 150,150\n",
        "        image = image.resize((width, height),resample = 0)\n",
        "        #Mendapatkan warna dari gambar\n",
        "        pixels = image.getcolors(width * height)\n",
        "        #Sort warna dari jumlah (first element of tuple)\n",
        "        sorted_pixels = sorted(pixels, key=lambda t: t[0])\n",
        "        #Mendapatkan warna yang paling sering muncul\n",
        "        dominant_color = sorted_pixels[-1][1]\n",
        "        return dominant_color\n",
        "\n",
        "def preprocess_img(img, imgSize):\n",
        "    \"put img into target img of size imgSize, transpose for TF and normalize gray-values\"\n",
        "    if img is None:\n",
        "        img = np.zeros([imgSize[1], imgSize[0]]) \n",
        "        print(\"Image None!\")\n",
        "\n",
        "    # Membuat target image\n",
        "    (wt, ht) = imgSize\n",
        "    (h, w) = img.shape\n",
        "    fx = w / wt\n",
        "    fy = h / ht\n",
        "    f = max(fx, fy)\n",
        "    newSize = (max(min(wt, int(w / f)), 1),\n",
        "               max(min(ht, int(h / f)), 1))  # scale according to f (result at least 1 and at most wt or ht)\n",
        "    img = cv2.resize(img, newSize, interpolation=cv2.INTER_CUBIC) # INTER_CUBIC interpolation best approximate the pixels image\n",
        "                                                               # see this https://stackoverflow.com/a/57503843/7338066\n",
        "    most_freq_pixel=find_dominant_color(Image.fromarray(img))\n",
        "    target = np.ones([ht, wt]) * most_freq_pixel  \n",
        "    target[0:newSize[1], 0:newSize[0]] = img\n",
        "\n",
        "    img = target\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sic3Urxs4OkE"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Data-generator-for-CRNN/annotation.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15004\\2739637020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mmax_label_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/Data-generator-for-CRNN/annotation.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mimagenames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtxts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Data-generator-for-CRNN/annotation.txt'"
          ]
        }
      ],
      "source": [
        "training_img = []\n",
        "training_txt = []\n",
        "train_input_length = []\n",
        "train_label_length = []\n",
        "orig_txt = []\n",
        " \n",
        "#lists untuk dataset validation\n",
        "valid_img = []\n",
        "valid_txt = []\n",
        "valid_input_length = []\n",
        "valid_label_length = []\n",
        "valid_orig_txt = []\n",
        " \n",
        "max_label_len = 0\n",
        "\n",
        "annot=open('/content/Data-generator-for-CRNN/annotation.txt','r').readlines()\n",
        "imagenames=[]\n",
        "txts=[]\n",
        "\n",
        "for cnt in annot:\n",
        "    filename,txt=cnt.split(',')[0],cnt.split(',')[1].split('\\n')[0]\n",
        "    imagenames.append(filename)\n",
        "    txts.append(txt)\n",
        "    \n",
        "c = list(zip(imagenames, txts))\n",
        "\n",
        "random.shuffle(c)\n",
        "\n",
        "imagenames, txts = zip(*c)\n",
        "    \n",
        "\n",
        "for i in range(len(imagenames)):\n",
        "        img = cv2.imread('/content/Data-generator-for-CRNN/images/'+imagenames[i],0)   \n",
        " \n",
        "        img=preprocess_img(img,(128,32))\n",
        "        img=np.expand_dims(img,axis=-1)\n",
        "        img = img/255.\n",
        "        txt = txts[i]\n",
        "        \n",
        "        # menghitung panjang maksimal text\n",
        "        if len(txt) > max_label_len:\n",
        "            max_label_len = len(txt)\n",
        "            \n",
        "        # split 150000 data menjadi 10% validation dan 90% training\n",
        "        if i%10 == 0:     \n",
        "            valid_orig_txt.append(txt)   \n",
        "            valid_label_length.append(len(txt))\n",
        "            valid_input_length.append(31)\n",
        "            valid_img.append(img)\n",
        "            valid_txt.append(encode(txt))\n",
        "        else:\n",
        "            orig_txt.append(txt)   \n",
        "            train_label_length.append(len(txt))\n",
        "            train_input_length.append(31)\n",
        "            training_img.append(img)\n",
        "            training_txt.append(encode(txt)) \n",
        "        \n",
        "        # Break loop jika total lebih dari 150000\n",
        "        if i == 150000:\n",
        "            flag = 1\n",
        "            break\n",
        "        i+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kp-U2u0p4Y_T"
      },
      "outputs": [],
      "source": [
        "#pad each output label to maximum text length\n",
        "train_padded_txt = pad_sequences(training_txt, maxlen=max_label_len, padding='post', value = len(char_list))\n",
        "valid_padded_txt = pad_sequences(valid_txt, maxlen=max_label_len, padding='post', value = len(char_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqWcDplF6HAt"
      },
      "outputs": [],
      "source": [
        "inputs = Input(shape=(32,128,1))\n",
        " \n",
        "# convolution layer with kernel size (3,3)\n",
        "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
        "# poolig layer with kernel size (2,2)\n",
        "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        " \n",
        "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
        "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        " \n",
        "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
        "\n",
        "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
        "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        " \n",
        "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
        "# Batch normalization layer\n",
        "batch_norm_5 = BatchNormalization()(conv_5)\n",
        " \n",
        "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
        "batch_norm_6 = BatchNormalization()(conv_6)\n",
        "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        "\n",
        " \n",
        "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
        " \n",
        "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        "\n",
        "# bidirectional LSTM layers with units=128\n",
        "blstm_1 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(squeezed)\n",
        "blstm_2 = Bidirectional(LSTM(128, return_sequences=True, dropout = 0.2))(blstm_1)\n",
        " \n",
        "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
        "\n",
        "# model untuk digunakan pada test time\n",
        "act_model = Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBtmnGNn6I0J",
        "outputId": "592d1f5a-8bc6-4467-ce3f-10ac61674d93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 128, 1)]      0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 128, 64)       640       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 64, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 64, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 32, 128)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 32, 256)        295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 32, 256)        590080    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 32, 256)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 4, 32, 512)        1180160   \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 4, 32, 512)       2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 4, 32, 512)        2359808   \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 4, 32, 512)       2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 32, 512)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 1, 31, 512)        1049088   \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 31, 512)           0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 31, 256)          656384    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 31, 256)          394240    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 31, 63)            16191     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,619,711\n",
            "Trainable params: 6,617,663\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "act_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMxpZweM6MfI"
      },
      "outputs": [],
      "source": [
        "labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        " \n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        " \n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, labels, input_length, label_length])\n",
        "\n",
        "#model untuk digunakan pada training time\n",
        "model = Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhqs_1FE6NYR"
      },
      "outputs": [],
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = 'adam')\n",
        " \n",
        "filepath=\"/content/best_model.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LhU9Lpj6QU-"
      },
      "outputs": [],
      "source": [
        "training_img = np.array(training_img)\n",
        "train_input_length = np.array(train_input_length)\n",
        "train_label_length = np.array(train_label_length)\n",
        "\n",
        "valid_img = np.array(valid_img)\n",
        "valid_input_length = np.array(valid_input_length)\n",
        "valid_label_length = np.array(valid_label_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx41yVYP9tQh",
        "outputId": "54d7b936-2558-4967-e0d4-5240e880bfc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 54.1516 \n",
            "Epoch 1: val_loss improved from inf to 41.37679, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 348s 31s/step - loss: 54.1516 - val_loss: 41.3768\n",
            "Epoch 2/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 39.8664 \n",
            "Epoch 2: val_loss improved from 41.37679 to 39.73097, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 336s 30s/step - loss: 39.8664 - val_loss: 39.7310\n",
            "Epoch 3/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 38.8598 \n",
            "Epoch 3: val_loss improved from 39.73097 to 39.50737, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 340s 31s/step - loss: 38.8598 - val_loss: 39.5074\n",
            "Epoch 4/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 37.5654 \n",
            "Epoch 4: val_loss improved from 39.50737 to 38.82055, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 337s 31s/step - loss: 37.5654 - val_loss: 38.8205\n",
            "Epoch 5/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 36.7509 \n",
            "Epoch 5: val_loss improved from 38.82055 to 38.41857, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 334s 30s/step - loss: 36.7509 - val_loss: 38.4186\n",
            "Epoch 6/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 36.5105 \n",
            "Epoch 6: val_loss improved from 38.41857 to 38.16573, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 336s 30s/step - loss: 36.5105 - val_loss: 38.1657\n",
            "Epoch 7/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 36.4268 \n",
            "Epoch 7: val_loss improved from 38.16573 to 38.01199, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 336s 31s/step - loss: 36.4268 - val_loss: 38.0120\n",
            "Epoch 8/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 36.3554 \n",
            "Epoch 8: val_loss improved from 38.01199 to 37.87552, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 335s 30s/step - loss: 36.3554 - val_loss: 37.8755\n",
            "Epoch 9/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 36.3381 \n",
            "Epoch 9: val_loss improved from 37.87552 to 37.49511, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 334s 30s/step - loss: 36.3381 - val_loss: 37.4951\n",
            "Epoch 10/15\n",
            "11/11 [==============================] - ETA: 0s - loss: 36.3204 \n",
            "Epoch 10: val_loss improved from 37.49511 to 37.21849, saving model to /content/best_model.hdf5\n",
            "11/11 [==============================] - 332s 30s/step - loss: 36.3204 - val_loss: 37.2185\n",
            "Epoch 11/15\n",
            " 7/11 [==================>...........] - ETA: 2:01 - loss: 36.5972"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 15\n",
        "model.fit(x=[training_img, train_padded_txt, train_input_length, train_label_length], y=np.zeros(len(training_img)), batch_size=batch_size, epochs = epochs, validation_data = ([valid_img, valid_padded_txt, valid_input_length, valid_label_length], [np.zeros(len(valid_img))]), verbose = 1, callbacks = callbacks_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pW4mPMB3MpCF"
      },
      "outputs": [],
      "source": [
        "# load the saved best model weights\n",
        "act_model.load_weights('best_model.hdf5')\n",
        " \n",
        "# predict outputs on validation images\n",
        "prediction = act_model.predict(valid_img[10:20])\n",
        " \n",
        "# use CTC decoder\n",
        "out = K.get_value(K.ctc_decode(prediction, input_length=np.ones(prediction.shape[0])*prediction.shape[1],\n",
        "                         greedy=True)[0][0])\n",
        " \n",
        "# results\n",
        "i = 10\n",
        "for x in out:\n",
        "    print(\"original_text =  \", valid_orig_txt[i])\n",
        "    print(\"predicted text = \", end = '')\n",
        "    for p in x:  \n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end = '')       \n",
        "    print('\\n')\n",
        "    i+=1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "0b33004c3e8d9917406a70462a053912537623a62a3051e4a5ecade0c4b22af5"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
